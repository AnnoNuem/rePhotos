#!/usr/bin/env python
"""Functions to find interesting lines near user drawn lines as well as
corresponding lines.
"""
import numpy as np
import cv2
from image_helpers import line_intersect 
from image_gabor import get_gabor



center_of_line = lambda p1, p2: np.array((np.float_((p1[0] + p2[0]))/2, 
                                          np.float_((p1[1] + p2[1]))/2))


def lim_line_length(p1_h, p2_h, p1_o, p2_o):
    """Limits length of line h to linesegment o.
    Computes a line segment of line h found by hough transform to the
    length of user drawn line segment o by computing the normals at start
    and end point of user drawn line segment and their intersection with
    hough line.

    Parameters
    ----------
    p1_h : ndarray
        First point on hough line.
    p2_h : ndarray
        Second point on hough line.
    p1_o : ndarray
        Startpoint of user drawn line segment.
    p2_o : ndarray
        Endpoint of user drawn line segment.

    Returns
    -------
    z1 : ndarray
        Startpoint of line segment of hough line.
    z2 : ndarray
        Endpoint of line segment of hough line.

    """
    p1_o = np.array(p1_o, dtype=np.float32)
    p2_o = np.array(p2_o, dtype=np.float32)
    p1_h = np.array(p1_h, dtype=np.float32)
    p2_h = np.array(p2_h, dtype=np.float32)
    # Compute end points of orthagonal lines
    b1_o = p1_o + np.array([-(p1_o[1] - p2_o[1]), (p1_o[0] - p2_o[0])])
    b2_o = p2_o + np.array([-(p2_o[1] - p1_o[1]), (p2_o[0] - p1_o[0])])
    z1 = line_intersect(p1_o, b1_o, p1_h, p2_h)
    z2 = line_intersect(p2_o, b2_o, p2_h, p1_h)
    z1 = (np.rint(z1)).astype(int)
    z2 = (np.rint(z2)).astype(int)
    return z1, z2


def get_theta(p1, p2):
    """Computes gradient angle of line.

    Parameters
    ----------
    p1 : ndarray
        First point of line.
    p2 : ndarray
        Second point of line.

    Returns
    -------
    theta : float64
        Gradient angle.

    """
    if p2[0] - p1[0] == 0:
        return 0
    else:
        m = (float(p2[1] - p1[1]) / float(p2[0] - p1[0]))
        return np.arctan(m) + np.pi/2


def weight_lines(patch_p, lines, p1_o, p2_o, max_delta=0.05, number_of_lines=10):
    """Weights hough lines by similarity to edges.
    Generates line segments with length according to user drawn lines and
    compares segments with edges in edge image. Select best matching line.
    Only lines with similar orientation to user drawn line are regarded.
    Only best ten lines fullfilling above criterium are considered.

    Parameters
    ----------
    patch_p : ndarray
        Edgeimage.
    lines :ndarray
        List of lines.
    p1_o : ndarray
        Startpoint of user drawn line.
    p2_o : ndarray
        Endpoint of user drawn line.
    max_delta : float
        max angle between given line and lines to be weighted. (Default value = 0.05)
    number_of_lines : int
        number of lines generated by first step (Default value = 10)

    Returns
    -------
    line_segs : ndarray
        best lines.
    weights : ndarray
        weights of the best line segments.

    """
    kernel = np.array([[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],
                       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],
                       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],
                       [0.50, 0.50, 0.00, 0.00, 0.00, 0.00, 0.00, 0.50, 0.50], 
                       [1.00, 1.00, 1.00, 1.00, 0.00, 1.00, 1.00, 1.00, 1.00], 
                       [0.50, 0.50, 0.00, 0.00, 0.00, 0.00, 0.00, 0.50, 0.50], 
                       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],
                       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],
                       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]],
                       dtype=np.float32)
    #define by hand, else floating point errors
    kernel_half = 4

    theta = np.pi - get_theta(p1_o, p2_o)
    m = cv2.getRotationMatrix2D((kernel_half, kernel_half), theta * 180 / np.pi -90, 1)
    kernel = cv2.warpAffine(kernel, m, kernel.shape)
    _patchf = cv2.filter2D(patch_p, cv2.CV_32F, kernel)
    _patchf[_patchf<1530] = 0 #6*255

    nl = min(number_of_lines, lines.shape[0])
    line_img = np.empty(patch_p.shape, dtype=np.uint8)
    weights = np.empty((nl), dtype=np.float32)
    line_segs = np.empty((nl), dtype=object)
    for i in range(0, nl):
        rho = lines[i][0][0]
        theta = lines[i][0][1]

        line_img[:] = 0
        a = np.cos(theta)
        b = np.sin(theta)
        x0, y0 = a * rho, b * rho
        pt1 = (int(x0 + 1000 * (-b)), int(y0 + 1000 * a))
        pt2 = (int(x0 - 1000 * (-b)), int(y0 - 1000 * a))
        pt1, pt2 = lim_line_length(pt1, pt2, p1_o, p2_o)

        cv2.line(line_img, (pt1[0], pt1[1]), (pt2[0], pt2[1]), 255, 1, 4)
        weights[i] = np.einsum('ij,ij->', line_img, _patchf, dtype=np.float32)
        line_segs[i] = (pt1, pt2)

    return line_segs, weights


def get_patch(img, p1, p2, psd=70):
    """Return image patch arround a given line.
    Return horizontal patch, a rectangular mask with same slope as the line and
    offset between min point of patch and image

    Parameters
    ----------
    img : ndarray
        Image from which the patch is generated
    p1 : tuple
        First point of the given line
    p2 : tuple
        Second point of the given line
    psd : int
        Patchsizedivisor (Default value = 70) determining the patch size i.e.
        the size arround the given line.

    Returns
    -------
    patch : ndarray
        Horizontal patch
    mask : ndarray
        Zero matrix of size patch with one rectangle determining the
        actual patch arround the line.
    offset : ndarray
        Offset between min point of patch and min point of image.

    """
    # Get length and slope of line
    length = np.sqrt((p1[1] - p2[1]) * (p1[1] - p2[1]) + (p1[0] - p2[0]) * 
        (p1[0] - p2[0])) 
    v = np.array([(p2[1] - p1[1])/length, (p2[0] - p1[0])/length], np.float32)

    # Compute rectangle with line in the middle and same rotation as line
    # and bounding box arround it
    s = (img.shape[0] + img.shape[1])/ np.float32(2 * psd)
    m1 = p1 + s * (v * [ 1, -1] - v[::-1]) 
    m2 = p1 + s * (v * [ -1, 1] - v[::-1]) 
    m3 = p2 + s * (v * [ -1, 1] + v[::-1])
    m4 = p2 + s * (v * [ 1, -1] + v[::-1])
    p = np.array([m1, m2, m3, m4], dtype=np.float32).T
    x_min = int(max(0, p[1,:].min()))
    x_max = int(min(img.shape[0], p[1,:].max()))
    y_min = int(max(0, p[0,:].min()))
    y_max = int(min(img.shape[1], p[0,:].max()))

    patch = img[x_min: x_max, y_min: y_max]

    # Generate mask of patch size
    mask = np.zeros((img.shape[0], img.shape[1]), dtype=patch.dtype)
    cv2.fillPoly(mask, [p.T.astype(int)], (1))
    mask = mask[x_min: x_max, y_min: y_max]
    
    offset = np.array([y_min, x_min])
    return patch, mask, offset


def line_detect(img, mask=None, sigma=0.33, magic_n=10, min_theta=0, 
                max_theta=np.pi):
    """Line detection on given image via Canny and Hough.
    Lines are limited to have an angle between min_theta and max_theta.

    Parameters
    ----------
    img : ndarray
        Image in which to detect lines.
    mask : ndarray
        Matrix of image size. Detection of lines only where mask is
        nonzero. (Default value = None)
    sigma : float
        Sigma for adpative Canny edge detection. (Default value = 0.33)
    magic_n : int
        Offset for adaptive Canny edge detection. (Default value = 10)
    min_theta : float64
         Minimum line angle for hough line detection.
         (Default value = 0)
    max_theta : float64
         Maximum line angle for hough line detection.
         (Default value = np.pi)

    Returns
    -------
    lines : ndarray
        Detected lines in Hesse normal form.

    """

    # Edge dedection
    m = np.median(img)
    lower_bound = int(max(0, (1.0 - sigma) * m)) + magic_n
    upper_bound = int(min(255, (1.0 + sigma) * m)) + magic_n
    img = cv2.Canny(img, lower_bound, upper_bound, L2gradient=True)

    # Filter patch_p to only contain the patch area not the containing rectangle
    if mask is not None:
        img[mask==0] = 0
    
    # Line detection
    lines = cv2.HoughLines(img, 1, np.pi/180.0, 1, np.array([]), 0, 0,
                          min_theta=min_theta, max_theta=max_theta)

    return lines, img


def get_line(p1, p2, img, psd=70):
    """Search in image for nearest most similar line of a given line.
    Search in H, S, and V for line in area around given line. Select line
    with similar rotation and many supporting edge pixels.

    Parameters
    ----------
    p1 : ndarray
        Start point of user drawn line.
    p2 : ndarray
        End point of user drawn line.
    img : ndarray
        Image in which nearest line in searched.
    psd : iny
        Patch size divisor: Area around line in which similar line is
        searched. Higher value = Smaller area (Default value = 70)

    Returns
    -------
    [p1,p2] : list
        List of two points of computed most similar line

    """

    # Get horizontal patch arround line and mask adapting to slope of line
    patch, mask, offset = get_patch(img, p1, p2, psd)

    # Offset points
    p1_o = p1 - offset
    p2_o = p2 - offset

    best_lines = get_weighted_lines(patch[:,:,0:3], mask, p1_o, p2_o)
    
    if len(best_lines) != 0:
        p1 = best_lines[0][0] + offset
        p2 = best_lines[0][1] + offset
    
    return [p1[0], p1[1], p2[0], p2[1]]


def get_transformed_patch(patch, p11, p12, p21, p22):
    """Rotates and translates given patch such that second line is mapped to a
    first horizontal line.

    Parameters
    ----------
    patch : ndarray
        Patch to be translated and rotated.
    p11 : tuple
        First point of first line.
    p12 : tuple
        Second point of first line.
    p21 : tuple
        First point of second line.
    p22 : tuple
        Second point of second line.

    Returns
    -------
    patch : ndarray
        Transformed patch.

    """
    delta = center_of_line(p11, p12) - center_of_line(p21, p22)

    t = get_theta(p21, p22) * 180 / np.pi - 90 
    size = np.int_(np.sqrt(patch.shape[0]**2 + patch.shape[1]**2))
    patch_ = np.zeros((size,size,patch.shape[2]), dtype=np.float32)
    patch_[(size-patch.shape[0])/2: (size-patch.shape[0])/2 + patch.shape[0],
           (size-patch.shape[1])/2: (size-patch.shape[1])/2 + patch.shape[1],
           :] = patch

    rm = cv2.getRotationMatrix2D((size/2, size/2), t, 1)
    tm = np.array([[1,0,delta[0]],[0,1,delta[1]]], dtype=np.float32)
    patch = cv2.warpAffine(patch_, tm, (size, size))
    patch = cv2.warpAffine(patch, rm, (size, size))

    return patch


def get_weighted_lines(img, mask, p1_o, p2_o, range_theta=1/12.*np.pi):
    """Returns sortet list of lines in proximity of a given line.
    Lines are sorted by line quality.

    Parameters
    ----------
    img : ndarray
        Image in which lines are searched.
    mask : ndarray
        Mask applied to image to limit search area.
    p1_o : ndarray
        First point of original line.
    p2_o : ndarray
        Second point of original line.
    range_theta : float
        Limits how far new lines are rotated from original line. 
        (Default value = 1/12.*np.pi)

    Returns
    -------
    best_lines : ndarray
        Array of lines in descending order.

    """
    _img = cv2.GaussianBlur(cv2.cvtColor(np.uint8(img), cv2.COLOR_BGR2HSV), 
                            (3,3), 0)
    # slope of given line to limit for hough theta
    theta_width_half = range_theta/2 
    theta = get_theta(p1_o, p2_o)
    min_theta = theta - theta_width_half
    max_theta = theta + theta_width_half

    best_lines = []
    weights = []
    for i in range(0,_img.shape[2]):
        lines, canny_img = line_detect(_img[:,:,i], mask, min_theta=min_theta, 
                                       max_theta=max_theta)
        if lines is not None:
            _lines, _weights = weight_lines(canny_img, lines, p1_o, p2_o)
            best_lines.append(_lines)
            weights.append(_weights)

    weights = np.array(weights).flatten()
    best_lines = np.array(best_lines).flatten()[np.argsort(weights)[::-1]]

    return best_lines

    
def get_corresponding_line(img1, img2, line1, psd=15, max_lines_to_check=60,
                           template_size=200):
    """Return a corresponding line in a second image given a line in a first image.
    Find max_lines_to_check lines in patch arround line1 in img2. Compare
    correspondence of found lines by template matching. Transform template in
    img2 such that found line in img2 and given line in img1 allign. Compute
    sum of squared differences and weight templates/lines.

    Parameters
    ----------
    img1 : ndarray
        Destination image in which line is already found
    img2 : ndarray
        Source image in which the corresponding line is searched
    line1 : list
        Line in img1 for which a corresponding line needs to be found
    psd : int
        Patchsizedivisor (Default value = 15)
    max_lines_to_check : int
        Number of lines which correspondence to given line is evaluated.
        (Default value = 60)
    template_size : int
        Size of template with which correspondence of line is determined.
        (Default value = 200)

    Returns
    -------
    list 
        The correspoding line.

    """

    p11 = (line1[0], line1[1])
    p12 = (line1[2], line1[3])
    patch, _, offset = get_patch(img1, p11, p12, psd)
    patch2, mask2, offset2 = get_patch(img2, p11, p12, psd)
    p11 = p11 - offset
    p12 = p12 - offset

    best_lines = get_weighted_lines(patch2, mask2, p11, p12, range_theta=1/8.*np.pi)

    # Compare lines in src image witch line in dst image  
    if len(best_lines) > 0:
        patch = cv2.cvtColor(np.float32(patch[:,:,0:3]), cv2.COLOR_BGR2HSV)
        patch2 = cv2.cvtColor(np.float32(patch2[:,:,0:3]), cv2.COLOR_BGR2HSV)

        weights_t = np.zeros((max_lines_to_check, 3), dtype=np.float32)

        # Scale patches, lines and points
        sf = template_size/np.float32((patch.shape[0] + patch.shape[1])/2)
        patch2 = np.float32(cv2.resize(patch2, (0,0), fx=sf, fy=sf))
        patch = np.float32(cv2.resize(patch, (0,0), fx=sf, fy=sf))
        p11_s = (p11[0]*sf, p11[1]*sf)
        p12_s = (p12[0]*sf, p12[1]*sf)
        best_lines_s = [tuple(point * sf for point in line) for line in\
                                                                best_lines]

        # Make dst patch horizontal
        t = get_theta(p11_s, p12_s) * 180 / np.pi - 90 
        size = np.int_(np.sqrt(patch.shape[0]**2 + patch.shape[1]**2))
        patch_ = np.zeros((size,size,patch.shape[2]), dtype=np.float32)
        patch_[(size-patch.shape[0])/2 : (size-patch.shape[0])/2 + patch.shape[0],
               (size-patch.shape[1])/2 : (size-patch.shape[1])/2 + patch.shape[1],
               :] = patch
        rm = cv2.getRotationMatrix2D((size/2, size/2), t, 1)
        patch = cv2.warpAffine(patch_, rm, (size, size))

        # Gabor Filter
        patch = cv2.normalize(get_gabor(patch),\
            patch, 0, 1, cv2.NORM_MINMAX)
        patch2 = cv2.normalize(get_gabor(patch2),\
            patch2, 0, 1, cv2.NORM_MINMAX)

        for i in range(0, min(max_lines_to_check, len(best_lines))):
            patch2_t = get_transformed_patch(np.copy(patch2), p11_s, p12_s,\
                       tuple(best_lines_s[i][0]), tuple(best_lines_s[i][1]))

            # Take only pixels which are non zero in both patches into account
            index = (patch2_t[:,:,2]!=0) * (patch[:,:,2]!=0)
            
            # Better results if only value channel is used compared to all three
            # channels.
            for j in range(2,3):
                weights_t[i][j] = np.sum((patch2_t[:,:,j][index] * patch[:,:,j][index]), dtype=np.float32) / np.sqrt(np.sum(patch2_t[:,:,j][index]**2, dtype=np.float32) * np.sum(patch[:,:,j][index]**2, dtype=np.float32))
        max_i = np.argmax(weights_t[0:i+1,2]) % (i+1)
        return np.array(best_lines[max_i]).flatten() + np.tile(offset2, 2)
    else:
        return None




